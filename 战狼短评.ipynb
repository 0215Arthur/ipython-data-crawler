{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载cookie\n",
      "xs\n",
      "[]\n",
      "{'source': 'index_nav', 'form_email': '15300523175', 'form_password': '@Zy107868'}\n",
      "登录成功\n",
      "------------------------下一个线程----------\n",
      "------------------------下一个线程----------\n",
      "1爬取下一页评论...\n",
      "?start=40&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "1爬取下一页评论...\n",
      "?start=164&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "2爬取下一页评论...\n",
      "2爬取下一页评论...?start=184&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "\n",
      "?start=60&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "3爬取下一页评论...\n",
      "?start=204&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "3爬取下一页评论...\n",
      "?start=80&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "4爬取下一页评论...\n",
      "?start=224&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "4爬取下一页评论...\n",
      "?start=100&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "5爬取下一页评论...\n",
      "休息...\n",
      "5爬取下一页评论...\n",
      "休息...\n",
      "?start=244&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "?start=120&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "6爬取下一页评论...\n",
      "?start=264&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "6爬取下一页评论...\n",
      "?start=140&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "7爬取下一页评论...\n",
      "?start=284&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "7爬取下一页评论...\n",
      "?start=160&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "8爬取下一页评论...\n",
      "?start=304&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "8爬取下一页评论...\n",
      "?start=180&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "9爬取下一页评论...\n",
      "?start=324&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "9爬取下一页评论...\n",
      "?start=200&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "10爬取下一页评论...\n",
      "?start=344&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "10爬取下一页评论...\n",
      "?start=220&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "11爬取下一页评论...11爬取下一页评论...\n",
      "\n",
      "休息...休息...\n",
      "\n",
      "?start=240&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=?start=364&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "\n",
      "12爬取下一页评论...\n",
      "?start=384&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "12爬取下一页评论...\n",
      "?start=260&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "13爬取下一页评论...\n",
      "?start=280&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "13爬取下一页评论...\n",
      "?start=404&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "14爬取下一页评论...\n",
      "?start=300&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "14爬取下一页评论...\n",
      "?start=424&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "15爬取下一页评论...\n",
      "?start=320&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "15爬取下一页评论...\n",
      "?start=444&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "16爬取下一页评论...\n",
      "?start=340&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "16爬取下一页评论...\n",
      "?start=464&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "17爬取下一页评论...\n",
      "休息...\n",
      "17爬取下一页评论...\n",
      "休息...\n",
      "?start=360&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "?start=484&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "18爬取下一页评论...\n",
      "?start=380&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "19爬取下一页评论...\n",
      "?start=400&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "20爬取下一页评论...\n",
      "?start=420&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "21爬取下一页评论...\n",
      "?start=440&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "22爬取下一页评论...\n",
      "?start=460&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "23爬取下一页评论...\n",
      "休息...\n",
      "?start=480&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "try:\n",
    "    import cookielib\n",
    "except:\n",
    "    import http.cookiejar as cookielib\n",
    "import re\n",
    "import time\n",
    "import os.path\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "try:\n",
    "    from PIL import Image\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# from mywordCloud import save_jieba_result\n",
    "# from mywordCloud import draw_wordcloud\n",
    "import threading\n",
    "import codecs\n",
    "# 构造 Request headers\n",
    "agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36'\n",
    "headers = {\n",
    "    \"Host\": \"www.douban.com\",\n",
    "    \"Referer\": \"https://www.douban.com/\",\n",
    "    'User-Agent': agent,\n",
    "}\n",
    "\n",
    "#使用cookie登录信息\n",
    "session=requests.session()\n",
    "session.cookies=cookielib.LWPCookieJar(filename='cook')\n",
    "\n",
    "try:\n",
    "    session.cookies.load(ignore_discard=True)\n",
    "    print('成功加载cookie')\n",
    "except:\n",
    "    print(\"cookie 未能加载\")\n",
    "\n",
    "# 获取验证码\n",
    "def get_captcha(url):\n",
    "    #获取验证码\n",
    "    print('获取验证码',url)\n",
    "    captcha_url = url\n",
    "    r = session.get(captcha_url, headers=headers)\n",
    "    print('test')\n",
    "    with open('captcha.jpg', 'wb') as f:\n",
    "        f.write(r.content)\n",
    "        f.close()\n",
    "    # 用pillow 的 Image 显示验证码\n",
    "    # 如果没有安装 pillow 到源代码所在的目录去找到验证码然后手动输入\n",
    "    try:\n",
    "        im = Image.open('captcha.jpg')\n",
    "        im.show()\n",
    "        im.close()\n",
    "    except:\n",
    "        print(u'请到 %s 目录找到captcha.jpg 手动输入' % os.path.abspath('captcha.jpg'))\n",
    "    captcha = input(\"please input the captcha\\n>\")\n",
    "    return captcha\n",
    "\n",
    "def isLogin():\n",
    "    #登录个人主页，查看是否登录成功\n",
    "    url='https://www.douban.com/people/151607908/'\n",
    "    login_code=session.get(url,headers=headers,allow_redirects=False).status_code\n",
    "    if login_code==200:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def login(acount,secret):\n",
    "    douban=\"https://www.douban.com/\"\n",
    "    htmlcha=session.get(douban,headers=headers).text\n",
    "    patterncha=r'id=\"captcha_image\" src=\"(.*?)\" alt=\"captcha\"'\n",
    "    httpcha=re.findall(patterncha,htmlcha)\n",
    "    pattern2=r'type=\"hidden\" name=\"captcha-id\" value=\"(.*?)\"'\n",
    "    hidden_value=re.findall(pattern2,htmlcha)\n",
    "    print(hidden_value)\n",
    "\n",
    "    post_data = {\n",
    "        \"source\": \"index_nav\",\n",
    "        'form_email': acount,\n",
    "        'form_password': secret\n",
    "    }\n",
    "    if len(httpcha)>0:\n",
    "        print('验证码连接',httpcha)\n",
    "        capcha=get_captcha(httpcha[0])\n",
    "        post_data['captcha-solution']=capcha\n",
    "        post_data['captcha-id']=hidden_value[0]\n",
    "\n",
    "    print (post_data)\n",
    "    post_url='https://www.douban.com/accounts/login'\n",
    "    login_page=session.post(post_url,data=post_data,headers=headers)\n",
    "    #保存cookies\n",
    "    session.cookies.save()\n",
    "\n",
    "    if isLogin():\n",
    "        print('登录成功')\n",
    "    else:\n",
    "        print('登录失败')\n",
    "\n",
    "#豆瓣评分等级\n",
    "gradeDic = {\n",
    "    '力荐':5,\n",
    "    '推荐':4,\n",
    "    '还行':3,\n",
    "    '较差':2,\n",
    "    '很差':1\n",
    "}\n",
    "        \n",
    "def get_movie_sort():\n",
    "    time.sleep(1)\n",
    "    movie_url='https://movie.douban.com/chart'\n",
    "    html=session.get(movie_url,headers=headers)\n",
    "    soup=BeautifulSoup(html.text,'html.parser')\n",
    "    result=soup.find_all('a',{'class':'nbg'})\n",
    "    print(result)\n",
    "\n",
    "# #爬取短评论\n",
    "# def get_comment(filename):  #filename为爬取得内容保存的文件\n",
    "#     begin=1\n",
    "#     next_url='?start=20&limit=20&sort=new_score&status=P'\n",
    "#     f=open(filename,'w+',encoding='utf-8')\n",
    "#     while(True):\n",
    "#         time.sleep(5)\n",
    "#         comment_url='https://movie.douban.com/subject/26363254/comments'\n",
    "#         data={\n",
    "#             'start':'27',\n",
    "#             'limit':'-20',\n",
    "#             'sort':'new_score',\n",
    "#             'status':'P'\n",
    "#         }\n",
    "#         headers2 = {\n",
    "#             \"Host\": \"movie.douban.com\",\n",
    "#             \"Referer\": \"https://www.douban.com/\",\n",
    "#             'User-Agent': agent,\n",
    "#             'Connection': 'keep-alive',\n",
    "#         }\n",
    "\n",
    "#         html=session.get(url='https://movie.douban.com/subject/26363254/comments'+next_url,headers=headers2)\n",
    "#         soup=BeautifulSoup(html.text,'html.parser')\n",
    "\n",
    "#         #爬取当前页面的所有评论\n",
    "#         result=soup.find_all('div',{'class':'comment'}) #爬取得所有的短评\n",
    "#         pattern4 = r'<p class=\"\"> (.*?)' \\\n",
    "#                    r'</p>'\n",
    "#         for item in result:\n",
    "#             s=str(item)\n",
    "#             count2=s.find('<p class=\"\">')\n",
    "#             count3=s.find('</p>')\n",
    "#             s2=s[count2+12:count3]  #抽取字符串中的评论\n",
    "#             if 'class' not in s2:\n",
    "#                 f.write(s2)\n",
    "\n",
    "#         #获取下一页的链接\n",
    "#         next_url=soup.find_all('div',{'id':'paginator'})\n",
    "#         pattern3=r'href=\"(.*?)\">后页'\n",
    "#         if(len(next_url)==0):\n",
    "#             break\n",
    "#         next_url=re.findall(pattern3,str(next_url[0]))  #得到后页的链接\n",
    "#         if(len(next_url)==0): #如果没有后页的链接跳出循环\n",
    "#             break\n",
    "#         next_url=next_url[0]\n",
    "#         print('%d爬取下一页评论...'%begin)\n",
    "#         begin=begin+1\n",
    "#         #如果爬取了6次则多休息2秒\n",
    "#         if(begin%6==0):\n",
    "#             time.sleep(30)\n",
    "#             print('休息...')\n",
    "#         print(next_url)\n",
    "#     f.close()\n",
    "\n",
    "#多线程爬虫，爬取豆瓣影评\n",
    "def thread_get_comment(comment_url):\n",
    "    next_url = '?start=19&limit=20&sort=new_score&status=P'\n",
    "    headers2 = {\n",
    "        \"Host\": \"movie.douban.com\",\n",
    "        \"Referer\": \"https://www.douban.com/\",\n",
    "        'User-Agent': agent,\n",
    "        'Connection': 'keep-alive',\n",
    "    }\n",
    "    filename='key.txt'\n",
    "    f = open(filename, 'w+', encoding='utf-8')\n",
    "    comment_url = 'https://movie.douban.com/subject/26363254/comments'\n",
    "    crawl_queue=[comment_url+next_url]\n",
    "    crawl_queue.append('https://movie.douban.com/subject/26363254/comments?start=144&limit=20&sort=new_score&status=P')\n",
    "    seen=set(crawl_queue)\n",
    "    seen=set(crawl_queue)\n",
    "\n",
    "    def process_queue():\n",
    "        begin = 1\n",
    "        while True:\n",
    "            try:\n",
    "                url=crawl_queue.pop()\n",
    "            except  IndexError:\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(20)\n",
    "                html = session.get(url=url,headers=headers2)\n",
    "                soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "                # 爬取当前页面的所有评论\n",
    "                result = soup.find_all('div', {'class': 'comment'})  # 爬取得所有的短评\n",
    "                pattern4 = r'<p class=\"\"> (.*?)' \\\n",
    "                           r'</p>'\n",
    "                for item in result:\n",
    "                    s = str(item)\n",
    "                    count2 = s.find('<p class=\"\">')\n",
    "                    count3 = s.find('</p>')\n",
    "                    s2 = s[count2 + 12:count3]  # 抽取字符串中的评论\n",
    "                    if 'class' not in s2:\n",
    "                        f.write(s2)\n",
    "\n",
    "                # 获取下一页的链接\n",
    "                next_url = soup.find_all('div', {'id': 'paginator'})\n",
    "                pattern3 = r'href=\"(.*?)\">后页'\n",
    "                if (len(next_url) == 0):\n",
    "                    break\n",
    "                next_url = re.findall(pattern3, str(next_url[0]))  # 得到后页的链接\n",
    "                if (len(next_url) == 0):  # 如果没有后页的链接跳出循环\n",
    "                    break\n",
    "                next_url = next_url[0]\n",
    "                print('%d爬取下一页评论...' % begin)\n",
    "                begin = begin + 1\n",
    "                # 如果爬取了6次则多休息2秒\n",
    "                if (begin % 6 == 0):\n",
    "                    print('休息...')\n",
    "                    time.sleep(30)\n",
    "\n",
    "                print(next_url)\n",
    "                if comment_url+next_url not in seen:\n",
    "                    seen.add(comment_url+next_url)\n",
    "                    crawl_queue.append(comment_url+next_url)\n",
    "\n",
    "    threads=[]\n",
    "    max_threads=5\n",
    "    while threads or crawl_queue:\n",
    "        for thread in threads:\n",
    "            if not thread.is_alive():\n",
    "                threads.remove(thread)\n",
    "        while len(threads)< max_threads and crawl_queue:\n",
    "            thread=threading.Thread(target=process_queue)\n",
    "            print('------------------------下一个线程----------')\n",
    "            thread.setDaemon(True) # set daemon so main thread can exit when receive ctrl + C\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "        time.sleep(2)\n",
    "\n",
    "\n",
    "    f.close()\n",
    "\n",
    "if __name__=='__main__':\n",
    "    if isLogin():\n",
    "        print('您已经登录')\n",
    "    else:\n",
    "        print('xs')\n",
    "        #login('name','psd')\n",
    "        login('15300523175','@Zy107868')\n",
    "    #get_comment('key.txt')  #单线程爬虫\n",
    "   \n",
    "    thread_get_comment('https://movie.douban.com/subject/25823277/collections')  #多线程爬虫\n",
    "    #save_jieba_result('key2.txt')\n",
    "    #draw_wordcloud('pjl_jieba.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载cookie\n",
      "xs\n",
      "[]\n",
      "{'source': 'index_nav', 'form_email': '_name', 'form_password': 'psd'}\n",
      "登录失败\n",
      "------------------------下一个线程----------\n",
      "https://movie.douban.com/subject/25823277/collections?start=4480\n",
      "224爬取下一页评论...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\admin\\Anaconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-7-ef754ff59704>\", line 214, in process_queue\n",
      "    info = comment.find('span',class_='comment-info')  # 获取用户和评分信息栏\n",
      "TypeError: find() takes no keyword arguments\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://movie.douban.com/subject/25823277/collections?start=4500\n",
      "225爬取下一页评论...\n",
      "https://movie.douban.com/subject/25823277/collections?start=4520\n",
      "226爬取下一页评论...\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载cookie\n",
      "xs\n",
      "['0ZPZByeQysrB4i3Qo7FW8sL8:en']\n",
      "验证码连接 ['https://www.douban.com/misc/captcha?id=0ZPZByeQysrB4i3Qo7FW8sL8:en&amp;size=s']\n",
      "获取验证码 https://www.douban.com/misc/captcha?id=0ZPZByeQysrB4i3Qo7FW8sL8:en&amp;size=s\n",
      "test\n",
      "please input the captcha\n",
      ">glass\n",
      "{'source': 'index_nav', 'form_email': '15300523175', 'form_password': '@Zy107868', 'captcha-solution': 'glass', 'captcha-id': '0ZPZByeQysrB4i3Qo7FW8sL8:en'}\n",
      "登录成功\n",
      "------------------------下一个线程----------\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "1爬取下一页评论...\n",
      "?start=20&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "推荐\n",
      "还行\n",
      "推荐\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "推荐\n",
      "力荐\n",
      "很差\n",
      "推荐\n",
      "较差\n",
      "很差\n",
      "2爬取下一页评论...\n",
      "?start=40&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "推荐\n",
      "推荐\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "还行\n",
      "推荐\n",
      "推荐\n",
      "推荐\n",
      "推荐\n",
      "较差\n",
      "推荐\n",
      "力荐\n",
      "力荐\n",
      "很差\n",
      "推荐\n",
      "很差\n",
      "推荐\n",
      "较差\n",
      "推荐\n",
      "3爬取下一页评论...\n",
      "?start=60&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "还行\n",
      "没有找到评分\n",
      "很差\n",
      "力荐\n",
      "很差\n",
      "推荐\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "推荐\n",
      "没有找到评分\n",
      "很差\n",
      "较差\n",
      "4爬取下一页评论...\n",
      "?start=80&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "还行\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "还行\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "还行\n",
      "5爬取下一页评论...\n",
      "休息...\n",
      "?start=100&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "较差\n",
      "还行\n",
      "很差\n",
      "没有找到评分\n",
      "较差\n",
      "很差\n",
      "较差\n",
      "还行\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "6爬取下一页评论...\n",
      "?start=120&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "推荐\n",
      "还行\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "还行\n",
      "推荐\n",
      "较差\n",
      "还行\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "7爬取下一页评论...\n",
      "?start=140&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "还行\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "推荐\n",
      "没有找到评分\n",
      "8爬取下一页评论...\n",
      "?start=160&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "很差\n",
      "还行\n",
      "还行\n",
      "很差\n",
      "推荐\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "推荐\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "没有找到评分\n",
      "9爬取下一页评论...\n",
      "?start=180&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "没有找到评分\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "还行\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "10爬取下一页评论...\n",
      "?start=200&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "很差\n",
      "没有找到评分\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "力荐\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "力荐\n",
      "很差\n",
      "很差\n",
      "还行\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "11爬取下一页评论...\n",
      "休息...\n",
      "?start=220&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "还行\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "较差\n",
      "较差\n",
      "12爬取下一页评论...\n",
      "?start=240&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "没有找到评分\n",
      "很差\n",
      "推荐\n",
      "较差\n",
      "力荐\n",
      "很差\n",
      "很差\n",
      "还行\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "力荐\n",
      "13爬取下一页评论...\n",
      "?start=260&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "还行\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "14爬取下一页评论...\n",
      "?start=280&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "没有找到评分\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "还行\n",
      "没有找到评分\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "还行\n",
      "很差\n",
      "推荐\n",
      "很差\n",
      "力荐\n",
      "很差\n",
      "15爬取下一页评论...\n",
      "?start=300&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "力荐\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "推荐\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "16爬取下一页评论...\n",
      "?start=320&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "还行\n",
      "没有找到评分\n",
      "17爬取下一页评论...\n",
      "休息...\n",
      "?start=340&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "力荐\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "力荐\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "较差\n",
      "18爬取下一页评论...\n",
      "?start=360&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "还行\n",
      "很差\n",
      "还行\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "还行\n",
      "没有找到评分\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "19爬取下一页评论...\n",
      "?start=380&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "力荐\n",
      "很差\n",
      "很差\n",
      "推荐\n",
      "较差\n",
      "很差\n",
      "较差\n",
      "力荐\n",
      "较差\n",
      "很差\n",
      "较差\n",
      "较差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "20爬取下一页评论...\n",
      "?start=400&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "较差\n",
      "还行\n",
      "推荐\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "还行\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "推荐\n",
      "很差\n",
      "还行\n",
      "很差\n",
      "21爬取下一页评论...\n",
      "?start=420&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "还行\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "没有找到评分\n",
      "很差\n",
      "较差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "22爬取下一页评论...\n",
      "?start=440&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "推荐\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "推荐\n",
      "很差\n",
      "还行\n",
      "很差\n",
      "还行\n",
      "力荐\n",
      "推荐\n",
      "还行\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "较差\n",
      "没有找到评分\n",
      "较差\n",
      "23爬取下一页评论...\n",
      "休息...\n",
      "?start=460&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "还行\n",
      "推荐\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "还行\n",
      "推荐\n",
      "没有找到评分\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "推荐\n",
      "较差\n",
      "很差\n",
      "推荐\n",
      "很差\n",
      "较差\n",
      "力荐\n",
      "很差\n",
      "24爬取下一页评论...\n",
      "?start=480&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=\n",
      "很差\n",
      "力荐\n",
      "很差\n",
      "很差\n",
      "还行\n",
      "较差\n",
      "很差\n",
      "很差\n",
      "很差\n",
      "没有找到评分\n",
      "很差\n",
      "没有找到评分\n",
      "较差\n",
      "还行\n",
      "很差\n",
      "推荐\n",
      "很差\n",
      "较差\n",
      "很差\n",
      "较差\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "try:\n",
    "    import cookielib\n",
    "except:\n",
    "    import http.cookiejar as cookielib\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import os.path\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "try:\n",
    "    from PIL import Image\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# from mywordCloud import save_jieba_result\n",
    "# from mywordCloud import draw_wordcloud\n",
    "import threading\n",
    "import codecs\n",
    "# 构造 Request headers\n",
    "agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36'\n",
    "headers = {\n",
    "    \"Host\": \"www.douban.com\",\n",
    "    \"Referer\": \"https://www.douban.com/\",\n",
    "    'User-Agent': agent,\n",
    "}\n",
    "\n",
    "#使用cookie登录信息\n",
    "session=requests.session()\n",
    "session.cookies=cookielib.LWPCookieJar(filename='cook')\n",
    "\n",
    "try:\n",
    "    session.cookies.load(ignore_discard=True)\n",
    "    print('成功加载cookie')\n",
    "except:\n",
    "    print(\"cookie 未能加载\")\n",
    "\n",
    "# 获取验证码\n",
    "def get_captcha(url):\n",
    "    #获取验证码\n",
    "    print('获取验证码',url)\n",
    "    captcha_url = url\n",
    "    r = session.get(captcha_url, headers=headers)\n",
    "    print('test')\n",
    "    with open('captcha.jpg', 'wb') as f:\n",
    "        f.write(r.content)\n",
    "        f.close()\n",
    "    # 用pillow 的 Image 显示验证码\n",
    "    # 如果没有安装 pillow 到源代码所在的目录去找到验证码然后手动输入\n",
    "    try:\n",
    "        im = Image.open('captcha.jpg')\n",
    "        im.show()\n",
    "        im.close()\n",
    "    except:\n",
    "        print(u'请到 %s 目录找到captcha.jpg 手动输入' % os.path.abspath('captcha.jpg'))\n",
    "    captcha = input(\"please input the captcha\\n>\")\n",
    "    return captcha\n",
    "\n",
    "def isLogin():\n",
    "    #登录个人主页，查看是否登录成功\n",
    "    url='https://www.douban.com/people/151607908/'\n",
    "    login_code=session.get(url,headers=headers,allow_redirects=False).status_code\n",
    "    if login_code==200:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#将内容存入excel\n",
    "def write_data(datas, name):\n",
    "    file_name = name\n",
    "    with open(file_name, 'a', errors='ignore', newline='') as f:\n",
    "            f_csv = csv.writer(f)\n",
    "            f_csv.writerows(datas)\n",
    "\n",
    "            \n",
    "def login(acount,secret):\n",
    "    douban=\"https://www.douban.com/\"\n",
    "    htmlcha=session.get(douban,headers=headers).text\n",
    "    patterncha=r'id=\"captcha_image\" src=\"(.*?)\" alt=\"captcha\"'\n",
    "    httpcha=re.findall(patterncha,htmlcha)\n",
    "    pattern2=r'type=\"hidden\" name=\"captcha-id\" value=\"(.*?)\"'\n",
    "    hidden_value=re.findall(pattern2,htmlcha)\n",
    "    print(hidden_value)\n",
    "\n",
    "    post_data = {\n",
    "        \"source\": \"index_nav\",\n",
    "        'form_email': acount,\n",
    "        'form_password': secret\n",
    "    }\n",
    "    if len(httpcha)>0:\n",
    "        print('验证码连接',httpcha)\n",
    "        capcha=get_captcha(httpcha[0])\n",
    "        post_data['captcha-solution']=capcha\n",
    "        post_data['captcha-id']=hidden_value[0]\n",
    "\n",
    "    print (post_data)\n",
    "    post_url='https://www.douban.com/accounts/login'\n",
    "    login_page=session.post(post_url,data=post_data,headers=headers)\n",
    "    #保存cookies\n",
    "    session.cookies.save()\n",
    "\n",
    "    if isLogin():\n",
    "        print('登录成功')\n",
    "    else:\n",
    "        print('登录失败')\n",
    "\n",
    "#豆瓣评分等级\n",
    "gradeDic = {\n",
    "    '力荐':5,\n",
    "    '推荐':4,\n",
    "    '还行':3,\n",
    "    '较差':2,\n",
    "    '很差':1\n",
    "}\n",
    "        \n",
    "def get_movie_sort():\n",
    "    time.sleep(1)\n",
    "    movie_url='https://movie.douban.com/chart'\n",
    "    html=session.get(movie_url,headers=headers)\n",
    "    soup=BeautifulSoup(html.text,'html.parser')\n",
    "    result=soup.find_all('a',{'class':'nbg'})\n",
    "    print(result)\n",
    "\n",
    "# #爬取短评论\n",
    "# def get_comment(filename):  #filename为爬取得内容保存的文件\n",
    "#     begin=1\n",
    "#     next_url='?start=20&limit=20&sort=new_score&status=P'\n",
    "#     f=open(filename,'w+',encoding='utf-8')\n",
    "#     while(True):\n",
    "#         time.sleep(5)\n",
    "#         comment_url='https://movie.douban.com/subject/26363254/comments'\n",
    "#         data={\n",
    "#             'start':'27',\n",
    "#             'limit':'-20',\n",
    "#             'sort':'new_score',\n",
    "#             'status':'P'\n",
    "#         }\n",
    "#         headers2 = {\n",
    "#             \"Host\": \"movie.douban.com\",\n",
    "#             \"Referer\": \"https://www.douban.com/\",\n",
    "#             'User-Agent': agent,\n",
    "#             'Connection': 'keep-alive',\n",
    "#         }\n",
    "\n",
    "#         html=session.get(url='https://movie.douban.com/subject/26363254/comments'+next_url,headers=headers2)\n",
    "#         soup=BeautifulSoup(html.text,'html.parser')\n",
    "\n",
    "#         #爬取当前页面的所有评论\n",
    "#         result=soup.find_all('div',{'class':'comment'}) #爬取得所有的短评\n",
    "#         pattern4 = r'<p class=\"\"> (.*?)' \\\n",
    "#                    r'</p>'\n",
    "#         for item in result:\n",
    "#             s=str(item)\n",
    "#             count2=s.find('<p class=\"\">')\n",
    "#             count3=s.find('</p>')\n",
    "#             s2=s[count2+12:count3]  #抽取字符串中的评论\n",
    "#             if 'class' not in s2:\n",
    "#                 f.write(s2)\n",
    "\n",
    "#         #获取下一页的链接\n",
    "#         next_url=soup.find_all('div',{'id':'paginator'})\n",
    "#         pattern3=r'href=\"(.*?)\">后页'\n",
    "#         if(len(next_url)==0):\n",
    "#             break\n",
    "#         next_url=re.findall(pattern3,str(next_url[0]))  #得到后页的链接\n",
    "#         if(len(next_url)==0): #如果没有后页的链接跳出循环\n",
    "#             break\n",
    "#         next_url=next_url[0]\n",
    "#         print('%d爬取下一页评论...'%begin)\n",
    "#         begin=begin+1\n",
    "#         #如果爬取了6次则多休息2秒\n",
    "#         if(begin%6==0):\n",
    "#             time.sleep(30)\n",
    "#             print('休息...')\n",
    "#         print(next_url)\n",
    "#     f.close()\n",
    "\n",
    "\n",
    "#多线程爬虫，爬取豆瓣影评\n",
    "def thread_get_comment(comment_url):\n",
    "    next_url = '?start=19&limit=20&sort=new_score&status=P'\n",
    "    headers2 = {\n",
    "        \"Host\": \"movie.douban.com\",\n",
    "        \"Referer\": \"https://www.douban.com/\",\n",
    "        'User-Agent': agent,\n",
    "        'Connection': 'keep-alive',\n",
    "    }\n",
    "   # f = open(filename, 'w+', encoding='utf-8')\n",
    "   # comment_url = 'https://movie.douban.com/subject/26363254/comments'\n",
    "    crawl_queue=[comment_url]\n",
    "    #crawl_queue.append(comment_url+'start=480&limit=20&sort=new_score&status=P&percent_type=')\n",
    "    #crawl_queue.append(comment_url+'?start=120&limit=20&sort=new_score&status=P&percent_type=')\n",
    "    seen=set(crawl_queue)\n",
    "\n",
    "    def process_queue():\n",
    "        begin = 1\n",
    "        while True:\n",
    "            try:\n",
    "                url=crawl_queue.pop()\n",
    "            except  IndexError:\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(5)\n",
    "                #,proxies={'https':'116.231.35.5:8118'}\n",
    "                html = session.get(url=url,headers=headers2,proxies={'http':'218.56.132.156:8080'})\n",
    "                #print (html.text)\n",
    "                final=[]\n",
    "                soup = BeautifulSoup(html.text, 'html.parser')\n",
    "                #bs4 = BeautifulSoup(html.text, 'html.parser').body.find(class_='sub_ins')#找到评论区\n",
    "                bs4 = soup.body.find('div',{'id':'comments'})#找到评论\n",
    "                #print (bs4)\n",
    "                \n",
    "                comment_lists = bs4.find_all('div',class_='comment')\n",
    "                for comment in comment_lists:\n",
    "                    temp = []\n",
    "                    info = comment.find('span',class_='comment-info')  # 获取用户和评分信息栏\n",
    "                    username = [text for text in info.find('a').stripped_strings][0] # 获取用户名，去掉span！！\n",
    "                    userid=info.find('a').get('href')\n",
    "                    comment_time=info.find('span',class_='comment-time').get('title')\n",
    "                    data = comment.find('p')\n",
    "                    #12print (data)\n",
    "#                     _time = data[0].get_text()  # 获取用户评论时间\n",
    "#                     _time = re.search(r'[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]', _time)  # 正则表达\n",
    "                    if info.find(class_=re.compile(\"allstar\")) is not None:  # 找到评分栏\n",
    "                        temp.append(username)  # 添加用户信息\n",
    "                        #print (username)\n",
    "                        #temp.append(city)\n",
    "                        temp.append(userid)\n",
    "                        temp.append(comment_time)\n",
    "                        grade = info.find(class_=re.compile(\"allstar\")).get('title')  # 获取用户评分\n",
    "                        temp.append(grade)\n",
    "                        temp.append(gradeDic[grade])  # 将评分转为5分制\n",
    "                        print(grade)\n",
    "                    else:\n",
    "                        print(\"没有找到评分\")\n",
    "                        continue\n",
    "                    if len(data) > 0:  # 如果用户评论不为空\n",
    "                        comment_s = data.text  # 获取用户评论\n",
    "                        temp.append(comment_s)\n",
    "                        #print(comment_s)\n",
    "                    else:\n",
    "                        #print(\"用户未评论\")\n",
    "                        temp.append(\"\")  # 留空\n",
    "                    final.append(temp)\n",
    "                write_data(final,'三生三世十里桃花.csv')\n",
    "            \n",
    "                next_url = soup.find_all('div', {'id': 'paginator'})\n",
    "                #next_url = bs4.find('div', {'id': 'paginator'}).find('a',class_='next').get('href')\n",
    "               # print (next_url)\n",
    "                pattern3 = r'href=\"(.*?)\">后页'\n",
    "                if (len(next_url) == 0):\n",
    "                    break\n",
    "                next_url = re.findall(pattern3, str(next_url[0]))  # 得到后页的链接\n",
    "                if (len(next_url) == 0):  # 如果没有后页的链接跳出循环\n",
    "                    break\n",
    "                next_url = next_url[0]\n",
    "                print('%d爬取下一页评论...' % begin)\n",
    "                begin = begin + 1\n",
    "                # 如果爬取了6次则多休息2秒\n",
    "                if (begin % 6 == 0):\n",
    "                    print('休息...')\n",
    "                    time.sleep(30)\n",
    "\n",
    "                print(next_url)\n",
    "                if comment_url+next_url not in seen:\n",
    "                    seen.add(comment_url+next_url)\n",
    "                    crawl_queue.append(comment_url+next_url)\n",
    "\n",
    "    threads=[]\n",
    "    max_threads=5\n",
    "    while threads or crawl_queue:\n",
    "        for thread in threads:\n",
    "            if not thread.is_alive():\n",
    "                threads.remove(thread)\n",
    "        while len(threads)< max_threads and crawl_queue:\n",
    "            thread=threading.Thread(target=process_queue)\n",
    "            print('------------------------下一个线程----------')\n",
    "            thread.setDaemon(True) # set daemon so main thread can exit when receive ctrl + C\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "        time.sleep(2)\n",
    "\n",
    "\n",
    "#    f.close()\n",
    "\n",
    "if __name__=='__main__':\n",
    "    if isLogin():\n",
    "        print('您已经登录')\n",
    "    else:\n",
    "        print('xs')\n",
    "        #login('_nafddgme','ffggpsd')\n",
    "        login('15300523175','@Zy107868')\n",
    "    #get_comment('key.txt')  #单线程爬虫\n",
    "    #comment_url = 'https://movie.douban.com/subject/26363254/comments\n",
    "    thread_get_comment('https://movie.douban.com/subject/25823277/comments')  #多线程爬虫\n",
    "    #save_jieba_result('key2.txt')\n",
    "    #draw_wordcloud('pjl_jieba.txt')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
